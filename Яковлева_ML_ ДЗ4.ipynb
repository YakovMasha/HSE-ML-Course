{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Базовый уровень: Генерация текста с использованием LSTM\n",
        "Сбор данных: используйте готовый или соберите свой корпус в формате plain text для генерации текстов\n",
        "\n",
        "Генерация текста на основе небольшого датасета\n",
        "\n",
        "Предварительный анализ: чистка текста\n",
        "\n",
        "Обучение модели. Используйте образец из туториала по RNNи\n",
        "Генерация текста. Используйте образец из туториала по RNN\n",
        "Сгенерируйте несколько текстов с помощью созданной модели"
      ],
      "metadata": {
        "id": "le1pGZbOK7MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я выбрала странный но интересный датасет на Кеггле - с русскими анекдотами (в превью вроде все прилично) https://www.kaggle.com/datasets/kdduha/russian-jokes"
      ],
      "metadata": {
        "id": "1X3shs1hS0Vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Подготовка: загружаем датасет, смотрим что там, вооружаемся библиотеками и тд."
      ],
      "metadata": {
        "id": "MXk91mrWM6Hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# вооружаемся\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sonnet as snt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "F5UddMUsLhSL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Установка Kaggle API\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Загрузка файла kaggle.json (предварительно загрузите его из своего аккаунта Kaggle)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Перемещение файла в нужную директорию\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Загрузка датасета\n",
        "!kaggle datasets download -d kdduha/russian-jokes\n",
        "\n",
        "# Распаковка архива\n",
        "!unzip russian-jokes.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "Dn6bgiXnPrCW",
        "outputId": "dc5d105d-ca74-447a-abdb-3395e6868fbe"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da4f1442-62a1-45b1-ad9b-9ade3177a8b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da4f1442-62a1-45b1-ad9b-9ade3177a8b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/kdduha/russian-jokes\n",
            "License(s): MIT\n",
            "russian-jokes.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  russian-jokes.zip\n",
            "replace russian_jokes.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: yes\n",
            "  inflating: russian_jokes.csv       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('russian_jokes.csv')  # посмотрим на загруженный через апи с кеггля датасет русскиз анекдотов (надеюсь, они приличные)\n",
        "print(df.head(15))"
      ],
      "metadata": {
        "id": "ddz8GNPSKRv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15ea263-f655-4246-9318-f838cbaaba17"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 text  comments_count  \\\n",
            "0   Директор отчитывает главбуха-еврея: \\n- Яков С...               0   \n",
            "1   — Изя, как вы думаете, объявления в газетах да...               0   \n",
            "2   Метро. На единственное свободное место садится...               2   \n",
            "3   Тюлька и килька вышли замуж за евреев. Теперь ...               2   \n",
            "4   Судился еврей с армянином. В итоге судье дали ...               2   \n",
            "5   — Вчера на меня напали грабители, отобрали кош...               0   \n",
            "6   Встречаются два однокурсника:\\n— Фима, не дава...               4   \n",
            "7   Набережная. \\nТурист потерявший кошелек громко...               0   \n",
            "8   На одной из одесских улиц, а именно, на Дериба...               0   \n",
            "9   Говорят, кошки ложатся на больное место. Сегод...               5   \n",
            "10  — Яша, что ты целый час уже суетишься?\\n— Не м...               5   \n",
            "11  В Одесском зоопарке мать\\nсыну:\\n- Зямочка, не...               1   \n",
            "12  Еврей вытаскивает из моря золотую рыбку. Она н...               0   \n",
            "13  Стоят два еврея на парковке: \\n— Изя, таки у н...               1   \n",
            "14  Мойша едет в машине. Он опаздывает на встречу ...               0   \n",
            "\n",
            "    likes_count  reposts_count  views_count                 date  \\\n",
            "0            72             23         2252  2024-01-12 17:22:00   \n",
            "1           118             43         5309  2024-01-12 13:21:00   \n",
            "2           143             38         4747  2024-01-12 09:20:00   \n",
            "3           287            116        12010  2024-01-12 05:20:15   \n",
            "4           632            267        19641  2024-01-11 21:14:00   \n",
            "5           170             71        11383  2024-01-11 19:14:00   \n",
            "6           113             23        10072  2024-01-11 17:13:00   \n",
            "7           105             22         4638  2024-01-11 15:13:00   \n",
            "8            94             22         7698  2024-01-11 13:12:00   \n",
            "9           171             42         9174  2024-01-11 11:12:00   \n",
            "10          119             43        10423  2024-01-11 09:11:00   \n",
            "11          125             11         8481  2024-01-11 07:11:00   \n",
            "12          315             88        12359  2024-01-11 05:10:00   \n",
            "13           82             15         9531  2024-01-11 03:09:00   \n",
            "14          156             54         8250  2024-01-11 01:09:00   \n",
            "\n",
            "                      unique_key               group_source  \n",
            "0   m3Cvn1OcrSBlJ_gABgIoRQBcyH0V  https://vk.com/jewishpugs  \n",
            "1   GPIii1u2kEabZEbnHqLTAyZA37ES  https://vk.com/jewishpugs  \n",
            "2   GJLahnmtLvVcc8x41sdV-lACQNPy  https://vk.com/jewishpugs  \n",
            "3   lBev3CChZteVPLaD1GHpYawoK5a4  https://vk.com/jewishpugs  \n",
            "4   I0rV0HbWhAkGHsnPNnBaONSUkKeX  https://vk.com/jewishpugs  \n",
            "5   Li-ZPFTr4ngPQNfMePHoKepnG2lb  https://vk.com/jewishpugs  \n",
            "6   eKZChXKzQrhypafPxdWT205QxAJI  https://vk.com/jewishpugs  \n",
            "7   MPqRSnST7fTOrvSokkNZlJbAej5R  https://vk.com/jewishpugs  \n",
            "8   NhnxJKU7yFLPI5SOUPohQJ4Xpk8j  https://vk.com/jewishpugs  \n",
            "9   g-u2-Hyexio02BAuRTCaG5ZA0e6a  https://vk.com/jewishpugs  \n",
            "10  JIzucI3LeURPSHWX37Ex6LlB1OvG  https://vk.com/jewishpugs  \n",
            "11  TSgOM_qRn8T6F2BQvBZACTj7CKgi  https://vk.com/jewishpugs  \n",
            "12  p3JF_cfRCTpNiWX5HlewJ13pQwAg  https://vk.com/jewishpugs  \n",
            "13  hse2RlL6qgAVXBjMW1xEySgxIxGx  https://vk.com/jewishpugs  \n",
            "14  WlhKYqUjfywHzZBLlOLMnA07iGst  https://vk.com/jewishpugs  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# еще смотрим структурность дс, кол-во строк и т.д.\n",
        "print(\"Информация о датасете:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTsmZ5D8LGCq",
        "outputId": "2685b463-304a-4f21-e562-a28df50cff61"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Информация о датасете:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 63927 entries, 0 to 63926\n",
            "Data columns (total 8 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   text            61685 non-null  object\n",
            " 1   comments_count  63927 non-null  int64 \n",
            " 2   likes_count     63927 non-null  int64 \n",
            " 3   reposts_count   63927 non-null  int64 \n",
            " 4   views_count     63927 non-null  int64 \n",
            " 5   date            63927 non-null  object\n",
            " 6   unique_key      63927 non-null  object\n",
            " 7   group_source    63927 non-null  object\n",
            "dtypes: int64(4), object(4)\n",
            "memory usage: 3.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# нас интересуют конечно же сами анекдоты - выбираем их в данные, называем отдельно в дф\n",
        "jokes = df['text'].tolist()\n",
        "jokes[:15]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0bX-m09LLCJ",
        "outputId": "bdc69cfd-6c77-4aab-e418-bde6b6fb8ff3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Директор отчитывает главбуха-еврея: \\n- Яков Самуилович, что за каменный век? У вас самый современный компьютер, а вы тарахтите счетами! Ну правда, перед клиентами стыдно! \\n- Роман Аркадьевич, таки шо я вам имею сказать за бухгалтерию. Я уже закрыл не одну финансовую проверку, когда вы ходили пешком под стол и уверяю вас, счеты куда надежнее этого компьютера. Представьте - врывается налоговая в офис: \"Всем к стене, руки за голову!\". И когда вы будете удалять документы из компьютера? А я таки поднимаю руки со счетами, все косточки съезжают на одну сторону и все! Никто ничего не докажет!',\n",
              " '— Изя, как вы думаете, объявления в газетах дают результаты?\\n— Конечно! В понедельник вышло объявление, что мы ищем сторожа, а уже во вторник нас ограбили!',\n",
              " 'Метро. На единственное свободное место садится классический, как их описывают в анекдоте, еврей. Нос. Очки. Взгляд печального спаниеля. Обращается к соседу:\\n— Вы еврей?\\n— Почему?\\n— Ваш ответ меня полностью удовлетворил.',\n",
              " 'Тюлька и килька вышли замуж за евреев. Теперь они мойва и сайра.',\n",
              " 'Судился еврей с армянином. В итоге судье дали пятнадцать лет.',\n",
              " '— Вчера на меня напали грабители, отобрали кошелек, часы…\\n— Изя! Но у тебя же медаль чемпиона по боксу!\\n— Медаль они не нашли…',\n",
              " 'Встречаются два однокурсника:\\n— Фима, не давай Рабиновичу в долг и не играй с ним в преферанс…\\n— Почему?\\n— Он увидел у меня в кошельке пятьсот рублей, занял пятьдесят до стипендии, а после этого выиграл на них остальные деньги…',\n",
              " 'Набережная. \\nТурист потерявший кошелек громко кричит: \\n— Потерян кошелек с 500 долларами, нашедшему даю пятьдесят долларов!\\nРядом останавливается Абрам:\\n— А я даю сто!',\n",
              " 'На одной из одесских улиц, а именно, на Дерибасовской, стояла заплаканная женщина. Иностранец, проходивший мимо, поинтересовался у нее: \\n— Что с вами случилось? \\nЖенщина отвечала: \\n—У меня украли кошелек с деньгами. \\nИностранец пожалел ее и дал ей деньги. \\nЖенщина стала его благодарить, а потом спросила:\\n— Может, вы и кошелек отдадите?',\n",
              " 'Говорят, кошки ложатся на больное место. Сегодня Изина кошка легла на его кошелек. Она ещё никогда не была так права…',\n",
              " '— Яша, что ты целый час уже суетишься?\\n— Не могу найти свой кошелек.\\n— А в брюках ты смотрел?\\n— Да.\\n— А в плаще?\\n— Смотрел.\\n— А во внутренних карманах?\\n— Нет.\\n— Почему?\\n— Если и там нет, у меня будет инфаркт...',\n",
              " 'В Одесском зоопарке мать\\nсыну:\\n- Зямочка, не трогай льва! У\\nнего могут быть блохи.',\n",
              " 'Еврей вытаскивает из моря золотую рыбку. Она на него внимательно смотрит. Спрашивает:\\n- Еврей?\\n- Таки да.\\n- Лучше зажарь.',\n",
              " 'Стоят два еврея на парковке: \\n— Изя, таки у нас похожие машины! И марка одна и та же, и модель, и цвет... Как мы их различать то будем?!\\n— Моня, всё очень просто! Смотрите: Моя справа, а ваша слева.\\n— Ну?\\n— А теперь поменяйте их местами.\\n— И?\\n— Видите? Моя слева, а вы моё место заняли...',\n",
              " 'Мойша едет в машине. Он опаздывает на встречу и никак не может найти, где припарковаться. В отчаянии он поднимает лицо вверх и говорит: \"Господи, если ты найдешь мне место для парковки, я обещаю, что буду есть только кошерное и буду уважать шаббат и все праздники\". \\n \\nЧудесным образом прямо перед ним открывается пространство. Он снова поднимает лицо и говорит: \"Все отбой, я только что нашел одно!\"']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Чистим дату"
      ],
      "metadata": {
        "id": "r3lNgpNyMzsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "\n",
        "# зачистка\n",
        "def clean_joke(joke):\n",
        "    if not isinstance(joke, str):  # проверка на нестроковые и NA\n",
        "        return \"\"\n",
        "    joke = ' '.join(joke.split()) # убиваем пробелы и переносы строк\n",
        "    joke = re.sub(r'[^\\w\\s.,!?-]', '', joke) #убираем всякие символы\n",
        "    return joke\n",
        "\n",
        "\n",
        "cleaned_jokes = [clean_joke(joke) for joke in jokes]\n",
        "\n",
        "# создаем новый дф для чистого материала\n",
        "cleaned_df = pd.DataFrame({'original_text': jokes, 'cleaned_text': cleaned_jokes})\n",
        "\n",
        "# проверка\n",
        "for i, joke in enumerate(cleaned_jokes[:5], 1):\n",
        "    print(f\"{i}. {joke}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hcNbqcXM4Gp",
        "outputId": "f6a3f292-b896-4aaf-d391-f58165dbc3c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Директор отчитывает главбуха-еврея - Яков Самуилович, что за каменный век? У вас самый современный компьютер, а вы тарахтите счетами! Ну правда, перед клиентами стыдно! - Роман Аркадьевич, таки шо я вам имею сказать за бухгалтерию. Я уже закрыл не одну финансовую проверку, когда вы ходили пешком под стол и уверяю вас, счеты куда надежнее этого компьютера. Представьте - врывается налоговая в офис Всем к стене, руки за голову!. И когда вы будете удалять документы из компьютера? А я таки поднимаю руки со счетами, все косточки съезжают на одну сторону и все! Никто ничего не докажет!\n",
            "\n",
            "2.  Изя, как вы думаете, объявления в газетах дают результаты?  Конечно! В понедельник вышло объявление, что мы ищем сторожа, а уже во вторник нас ограбили!\n",
            "\n",
            "3. Метро. На единственное свободное место садится классический, как их описывают в анекдоте, еврей. Нос. Очки. Взгляд печального спаниеля. Обращается к соседу  Вы еврей?  Почему?  Ваш ответ меня полностью удовлетворил.\n",
            "\n",
            "4. Тюлька и килька вышли замуж за евреев. Теперь они мойва и сайра.\n",
            "\n",
            "5. Судился еврей с армянином. В итоге судье дали пятнадцать лет.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tffwLn2pQJTE",
        "outputId": "75ef0550-eb18-466f-ad32-648e3a79b314"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 63927 entries, 0 to 63926\n",
            "Data columns (total 2 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   original_text  61685 non-null  object\n",
            " 1   cleaned_text   63927 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 999.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corp = cleaned_jokes[:len(cleaned_jokes)//15] # сократим чтобы не нервировать Cpu в гугл колабе и не ждать 100500 часов"
      ],
      "metadata": {
        "id": "bAmVtg3_RIFQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower_corp = [text.lower() for text in corp]\n",
        "print(lower_corp[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlOSJ7_UR2pn",
        "outputId": "d82542ee-763f-41b0-cf6e-0df1f91a1616"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "крупный фабрикант приходит к раввину  ребе, у меня проблемы. фабрика приносит одни убытки, дисциплины никакой, производительность на нуле, долги растут, налоги заели. что делать?  возьми талмуд, положи его подмышку и обходи всю фабрику два раза в день. через месяц приходит радостный фабрикант к раввину и говорит  замечательно, воровство на работе прекратилось, бездельники уволены, производительность выросла, с долгами покончено! в чем секрет?  руководитель должен постоянно находиться у себя на производстве и вникать во все, что происходит.  это я понял. а талмуд зачем?  для солидности...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Обучаем"
      ],
      "metadata": {
        "id": "BdFLzxwCT1NF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# инициация токенайзера\n",
        "tokenizer = Tokenizer(num_words=10000, oov_token=\"\")\n",
        "tokenizer.fit_on_texts(lower_corp)\n",
        "sequences = tokenizer.texts_to_sequences(lower_corp)"
      ],
      "metadata": {
        "id": "fWmiCimvT0cj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([lower_corp[0]])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug-PwLrHUF0G",
        "outputId": "dd6d1f71-1ba6-4048-c478-51fb16a3da70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1339,\n",
              " 8232,\n",
              " 8233,\n",
              " 60,\n",
              " 363,\n",
              " 8234,\n",
              " 8,\n",
              " 15,\n",
              " 8235,\n",
              " 8236,\n",
              " 10,\n",
              " 37,\n",
              " 274,\n",
              " 8237,\n",
              " 1449,\n",
              " 6,\n",
              " 9,\n",
              " 8238,\n",
              " 4950,\n",
              " 25,\n",
              " 224,\n",
              " 156,\n",
              " 6422,\n",
              " 1107,\n",
              " 3176,\n",
              " 8239,\n",
              " 17,\n",
              " 21,\n",
              " 7,\n",
              " 49,\n",
              " 1340,\n",
              " 210,\n",
              " 15,\n",
              " 8240,\n",
              " 7,\n",
              " 43,\n",
              " 688,\n",
              " 4,\n",
              " 357,\n",
              " 6423,\n",
              " 8241,\n",
              " 50,\n",
              " 9,\n",
              " 2377,\n",
              " 3869,\n",
              " 151,\n",
              " 739,\n",
              " 2,\n",
              " 2126,\n",
              " 37,\n",
              " 8242,\n",
              " 358,\n",
              " 8243,\n",
              " 190,\n",
              " 4951,\n",
              " 4952,\n",
              " 6424,\n",
              " 3177,\n",
              " 3,\n",
              " 1450,\n",
              " 325,\n",
              " 19,\n",
              " 825,\n",
              " 464,\n",
              " 15,\n",
              " 530,\n",
              " 2,\n",
              " 50,\n",
              " 9,\n",
              " 229,\n",
              " 3178,\n",
              " 1252,\n",
              " 28,\n",
              " 4951,\n",
              " 6,\n",
              " 7,\n",
              " 17,\n",
              " 4953,\n",
              " 464,\n",
              " 139,\n",
              " 4950,\n",
              " 33,\n",
              " 8244,\n",
              " 8245,\n",
              " 5,\n",
              " 357,\n",
              " 875,\n",
              " 2,\n",
              " 33,\n",
              " 551,\n",
              " 100,\n",
              " 4,\n",
              " 8246]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "MAX_SAMPLES = 30000\n",
        "\n",
        "for seq in sequences:\n",
        "    for i in range(1, len(seq)):\n",
        "        X.append(seq[:i])\n",
        "        y.append(seq[i])\n",
        "        if len(X) >= MAX_SAMPLES:\n",
        "            break\n",
        "    if len(X) >= MAX_SAMPLES:\n",
        "        break"
      ],
      "metadata": {
        "id": "74qmkmNqUOrx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(snt.RNNCore):\n",
        "\n",
        "  # инициация параметров RNN\n",
        "  def __init__(self, hidden_size, activation=tf.tanh, name=\"vanilla_rnn\"):\n",
        "    \"\"\"\n",
        "    hidden_size: размер скрытого слоя\n",
        "    activation: тип функции активации\n",
        "    name: название модели\n",
        "    \"\"\"\n",
        "    # вызов конструктора родительского класса (snt.RNNCore)\n",
        "    super(RNN, self).__init__(name=name)\n",
        "\n",
        "    # сохранение размера скрытого состояния\n",
        "    self._hidden_size = hidden_size\n",
        "\n",
        "    # сохранение активации\n",
        "    self._activation = activation"
      ],
      "metadata": {
        "id": "vYQpyViAUUJE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _build(self, input_, prev_state):\n",
        "    \"\"\"\n",
        "    input_: тензор с текущим x_t\n",
        "    prev_tate: тезор с h_{t-1}\n",
        "    \"\"\"\n",
        "    # Создаем линейный слой для преобразования входных данных в скрытое состояние\n",
        "    self._in_to_hidden_linear = snt.Linear(\n",
        "        self._hidden_size, name=\"in_to_hidden\")\n",
        "\n",
        "    # Создаем линейный слой для преобразования предыдущего скрытого состояния в новое\n",
        "    self._hidden_to_hidden_linear = snt.Linear(\n",
        "        self._hidden_size, name=\"hidden_to_hidden\")\n",
        "\n",
        "    # Применяем линейное преобразование к входным данным\n",
        "    in_to_hidden = self._in_to_hidden_linear(input_)\n",
        "\n",
        "    # Применяем линейное преобразование к предыдущему скрытому состоянию\n",
        "    hidden_to_hidden = self._hidden_to_hidden_linear(prev_state)\n",
        "\n",
        "    # Складываем результаты и применяем функцию активации\n",
        "    output = self._activation(in_to_hidden + hidden_to_hidden)\n",
        "\n",
        "    # Возвращаем выходное значение и новое скрытое состояние\n",
        "    return output, output\n",
        "\n",
        "# Свойство state_size возвращает размерность скрытого состояния\n",
        "@property\n",
        "def state_size(self):\n",
        "    return tf.TensorShape([self._hidden_size])\n",
        "\n",
        "# Свойство output_size возвращает размерность выходного значения\n",
        "@property\n",
        "def output_size(self):\n",
        "    return tf.TensorShape([self._hidden_size])"
      ],
      "metadata": {
        "id": "6WvrUn-CV20e"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "max_sequence_len = max([len(x) for x in X])\n",
        "X = pad_sequences(X, maxlen=max_sequence_len, padding='pre')\n",
        "y = np.array(y)\n",
        "y = to_categorical(y, num_classes=len(tokenizer.word_index) + 1)"
      ],
      "metadata": {
        "id": "VnrjqbA6WAY6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Создаем модель\n",
        "model = Sequential()\n",
        "\n",
        "# Добавляем слой Embedding\n",
        "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_len))\n",
        "\n",
        "# Добавляем слой LSTM\n",
        "model.add(LSTM(150, return_sequences=False))\n",
        "\n",
        "# Добавляем полносвязный слой\n",
        "model.add(Dense(len(tokenizer.word_index) + 1, activation='softmax'))\n",
        "\n",
        "# Компилируем модель\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Выводим информацию о модели\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "i5-3GhA9WxxS",
        "outputId": "acc45497-e3dd-4015-9757-8a031facaecd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Теперь можно обучать модель\n",
        "# экстра коммент - сначала я уменьшила размер на 3, потом на4, потом на 5 и так до 15 - только так норм заработало(хотя все равно долговато)... но может оно и к лучшему :) вышло 3~ часа\n",
        "history = model.fit(X, y, epochs=50, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "id": "O1imK1V6XmnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75784c8d-886e-4cc2-e97c-8664a25ba7a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m231s\u001b[0m 609ms/step - accuracy: 0.0274 - loss: 8.3403 - val_accuracy: 0.0298 - val_loss: 7.7864\n",
            "Epoch 2/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 616ms/step - accuracy: 0.0310 - loss: 7.3010 - val_accuracy: 0.0448 - val_loss: 7.8659\n",
            "Epoch 3/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 591ms/step - accuracy: 0.0476 - loss: 7.0032 - val_accuracy: 0.0518 - val_loss: 7.9471\n",
            "Epoch 4/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 567ms/step - accuracy: 0.0586 - loss: 6.6968 - val_accuracy: 0.0502 - val_loss: 8.0284\n",
            "Epoch 5/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 582ms/step - accuracy: 0.0601 - loss: 6.4086 - val_accuracy: 0.0502 - val_loss: 8.1290\n",
            "Epoch 6/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 574ms/step - accuracy: 0.0687 - loss: 6.0838 - val_accuracy: 0.0547 - val_loss: 8.2271\n",
            "Epoch 7/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 569ms/step - accuracy: 0.0745 - loss: 5.7575 - val_accuracy: 0.0570 - val_loss: 8.3299\n",
            "Epoch 8/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 569ms/step - accuracy: 0.0912 - loss: 5.4275 - val_accuracy: 0.0598 - val_loss: 8.4299\n",
            "Epoch 9/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 577ms/step - accuracy: 0.1142 - loss: 5.1298 - val_accuracy: 0.0648 - val_loss: 8.5270\n",
            "Epoch 10/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 578ms/step - accuracy: 0.1444 - loss: 4.8170 - val_accuracy: 0.0722 - val_loss: 8.6424\n",
            "Epoch 11/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 578ms/step - accuracy: 0.1794 - loss: 4.5270 - val_accuracy: 0.0737 - val_loss: 8.7188\n",
            "Epoch 12/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 582ms/step - accuracy: 0.2265 - loss: 4.2407 - val_accuracy: 0.0835 - val_loss: 8.7900\n",
            "Epoch 13/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 573ms/step - accuracy: 0.2841 - loss: 3.9449 - val_accuracy: 0.0865 - val_loss: 8.9011\n",
            "Epoch 14/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 569ms/step - accuracy: 0.3291 - loss: 3.6899 - val_accuracy: 0.0950 - val_loss: 8.9811\n",
            "Epoch 15/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 574ms/step - accuracy: 0.3781 - loss: 3.4276 - val_accuracy: 0.0982 - val_loss: 9.0370\n",
            "Epoch 16/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 580ms/step - accuracy: 0.4215 - loss: 3.1534 - val_accuracy: 0.1022 - val_loss: 9.1167\n",
            "Epoch 17/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 580ms/step - accuracy: 0.4656 - loss: 2.9173 - val_accuracy: 0.1082 - val_loss: 9.2166\n",
            "Epoch 18/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 579ms/step - accuracy: 0.5035 - loss: 2.6860 - val_accuracy: 0.1102 - val_loss: 9.2812\n",
            "Epoch 19/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 570ms/step - accuracy: 0.5347 - loss: 2.5138 - val_accuracy: 0.1122 - val_loss: 9.3707\n",
            "Epoch 20/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 582ms/step - accuracy: 0.5696 - loss: 2.3058 - val_accuracy: 0.1178 - val_loss: 9.4532\n",
            "Epoch 21/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 578ms/step - accuracy: 0.6013 - loss: 2.1371 - val_accuracy: 0.1218 - val_loss: 9.5268\n",
            "Epoch 22/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 578ms/step - accuracy: 0.6300 - loss: 1.9822 - val_accuracy: 0.1273 - val_loss: 9.6124\n",
            "Epoch 23/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 569ms/step - accuracy: 0.6561 - loss: 1.8455 - val_accuracy: 0.1288 - val_loss: 9.7041\n",
            "Epoch 24/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 581ms/step - accuracy: 0.6815 - loss: 1.7121 - val_accuracy: 0.1297 - val_loss: 9.7834\n",
            "Epoch 25/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 574ms/step - accuracy: 0.7105 - loss: 1.5715 - val_accuracy: 0.1303 - val_loss: 9.8702\n",
            "Epoch 26/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 578ms/step - accuracy: 0.7244 - loss: 1.4746 - val_accuracy: 0.1343 - val_loss: 9.9449\n",
            "Epoch 27/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 586ms/step - accuracy: 0.7528 - loss: 1.3512 - val_accuracy: 0.1358 - val_loss: 10.0410\n",
            "Epoch 28/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 580ms/step - accuracy: 0.7721 - loss: 1.2523 - val_accuracy: 0.1398 - val_loss: 10.1197\n",
            "Epoch 29/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 583ms/step - accuracy: 0.7860 - loss: 1.1627 - val_accuracy: 0.1395 - val_loss: 10.2092\n",
            "Epoch 30/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 579ms/step - accuracy: 0.8107 - loss: 1.0598 - val_accuracy: 0.1403 - val_loss: 10.2655\n",
            "Epoch 31/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 572ms/step - accuracy: 0.8270 - loss: 0.9716 - val_accuracy: 0.1442 - val_loss: 10.3641\n",
            "Epoch 32/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 574ms/step - accuracy: 0.8362 - loss: 0.9166 - val_accuracy: 0.1480 - val_loss: 10.4590\n",
            "Epoch 33/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 581ms/step - accuracy: 0.8578 - loss: 0.8336 - val_accuracy: 0.1458 - val_loss: 10.5362\n",
            "Epoch 34/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 577ms/step - accuracy: 0.8678 - loss: 0.7689 - val_accuracy: 0.1495 - val_loss: 10.6317\n",
            "Epoch 35/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 573ms/step - accuracy: 0.8806 - loss: 0.7076 - val_accuracy: 0.1513 - val_loss: 10.7403\n",
            "Epoch 36/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 587ms/step - accuracy: 0.8890 - loss: 0.6500 - val_accuracy: 0.1483 - val_loss: 10.7915\n",
            "Epoch 37/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 590ms/step - accuracy: 0.8999 - loss: 0.6026 - val_accuracy: 0.1512 - val_loss: 10.8889\n",
            "Epoch 38/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 588ms/step - accuracy: 0.9119 - loss: 0.5426 - val_accuracy: 0.1522 - val_loss: 10.9714\n",
            "Epoch 39/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 590ms/step - accuracy: 0.9212 - loss: 0.4946 - val_accuracy: 0.1543 - val_loss: 11.0926\n",
            "Epoch 40/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 593ms/step - accuracy: 0.9279 - loss: 0.4641 - val_accuracy: 0.1545 - val_loss: 11.1317\n",
            "Epoch 41/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 599ms/step - accuracy: 0.9326 - loss: 0.4243 - val_accuracy: 0.1535 - val_loss: 11.2512\n",
            "Epoch 42/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 598ms/step - accuracy: 0.9417 - loss: 0.3855 - val_accuracy: 0.1532 - val_loss: 11.3440\n",
            "Epoch 43/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 598ms/step - accuracy: 0.9453 - loss: 0.3545 - val_accuracy: 0.1535 - val_loss: 11.4222\n",
            "Epoch 44/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 588ms/step - accuracy: 0.9518 - loss: 0.3259 - val_accuracy: 0.1558 - val_loss: 11.5187\n",
            "Epoch 45/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 589ms/step - accuracy: 0.9559 - loss: 0.2953 - val_accuracy: 0.1587 - val_loss: 11.6194\n",
            "Epoch 46/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 588ms/step - accuracy: 0.9580 - loss: 0.2752 - val_accuracy: 0.1562 - val_loss: 11.6757\n",
            "Epoch 47/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 586ms/step - accuracy: 0.9662 - loss: 0.2455 - val_accuracy: 0.1572 - val_loss: 11.7787\n",
            "Epoch 48/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 583ms/step - accuracy: 0.9667 - loss: 0.2226 - val_accuracy: 0.1572 - val_loss: 11.8482\n",
            "Epoch 49/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 591ms/step - accuracy: 0.9712 - loss: 0.2053 - val_accuracy: 0.1582 - val_loss: 11.9283\n",
            "Epoch 50/50\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 588ms/step - accuracy: 0.9711 - loss: 0.1908 - val_accuracy: 0.1592 - val_loss: 12.0302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "IrSfheA4QPZb",
        "outputId": "cc83a0c5-4ebe-454a-8b5e-36b2bb3b0ddd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │     \u001b[38;5;34m1,491,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m150\u001b[0m)              │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m14916\u001b[0m)            │     \u001b[38;5;34m2,252,316\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,491,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14916</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,252,316</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,683,550\u001b[0m (44.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,683,550</span> (44.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,894,516\u001b[0m (14.86 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,894,516</span> (14.86 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m7,789,034\u001b[0m (29.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,789,034</span> (29.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "\n",
        "        output_word = ''\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += ' ' + output_word\n",
        "    return seed_text\n",
        "\n",
        "generated = generate_text(\"товарищ\", 25, max_sequence_len)\n",
        "print(generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ew-RNzuQV5n",
        "outputId": "e4e24e79-761d-4536-b3c3-fbd4175878ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "товарищ рабинович вы любите родину конечно люблю от всей души а вы готовы отдать за нее жизнь вы меня конечно извините но кто же тогда будет\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# еще генерируем\n",
        "def generate_multiple_texts(seed_texts, next_words, max_sequence_len):\n",
        "    generated_texts = []\n",
        "    for seed_text in seed_texts:\n",
        "        generated_text = generate_text(seed_text, next_words, max_sequence_len)\n",
        "        generated_texts.append(generated_text)\n",
        "    return generated_texts\n",
        "\n",
        "seed_texts = [\n",
        "    \"мой\",\n",
        "    \"город\",\n",
        "    \"я\",\n",
        "    \"документ\",\n",
        "    \"едет\",\n",
        "    \"стоматолог\",\n",
        "    \"здесь\"\n",
        "]\n",
        "\n",
        "generated_texts = generate_multiple_texts(seed_texts, next_words=25, max_sequence_len=max_sequence_len)\n",
        "\n",
        "for i, generated_text in enumerate(generated_texts):\n",
        "    print(f\"Generated text {i+1}:\\n{generated_text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42UGLscbQwGg",
        "outputId": "2fc23d18-3572-4950-88a0-0ff1710b2db9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text 1:\n",
            "мой в израильском фейсбуке выйду замуж за еврея любой национальности сдохшего льва и скажите ну что честно они тебя не стоишь а шо вы то на\n",
            "\n",
            "Generated text 2:\n",
            "город на памятнике здесь покоится известный одесский стоматолог борис рафаилович кац а его сын моня принимает в его кабинете на прохоровской 21 что случилось люди на\n",
            "\n",
            "Generated text 3:\n",
            "я передумал и в израиль не поеду вы же уже документы получили тур оплатили не поеду я но почему там плюс 40 в тени ну а\n",
            "\n",
            "Generated text 4:\n",
            "документ в                        \n",
            "\n",
            "Generated text 5:\n",
            "едет на тот напали грабители на пороге смотрит и начинает показать язык есть больше я не обоев покупали когда делали свой ремонт он пошел ему деньги\n",
            "\n",
            "Generated text 6:\n",
            "стоматолог еврея мюнхен сильно пострадал от голубей в результате эпидемии у птиц случилась диарея и голубиный помет усеял крыши мэрия мюнхена ежедневно тратила большие суммы для\n",
            "\n",
            "Generated text 7:\n",
            "здесь е годы рабинович в                     \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Сохраняем модель\n",
        "model.save('news_headline_generator.keras')"
      ],
      "metadata": {
        "id": "yKcUdmViRsx5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выводы:\n",
        "очень интересный и забавный эксперимент получился - пришлось подбирать и максимальные токены, и объем датасета. Наверное уже потом вне курса попробую что-то подобное, но в реалиях более длинного промежутка времени на обучения.\n",
        "Видно, что точность недотягивает в моем итоговом варианте - но в большинстве случае с более трудоемкими настройками среды вылетала, так что довольствуюсь малым.\n",
        "В целом - модель хорошо уловила стиль датасета - немного больше \"еврейской\" тематики чем я ожидала. Конечно, чем менее частотное слово, тем меньше контектса он ловит и генерирует большую околесицу. Любопытно, что в 6 примере дважды был мюнхен, и даже была последовательность вполне читаемая (хотя и не очень приличная)\n",
        "По обучению - оноо получилось не очень эффективно, но была возможность оставить думать на 3,5 часа - после ухищрений с длиной датасета, эпохами, токенами. В целом, получилось забавно и стиль \"русского анекдота\" модель сохранила при генерации."
      ],
      "metadata": {
        "id": "SdH1BJPlgbwJ"
      }
    }
  ]
}